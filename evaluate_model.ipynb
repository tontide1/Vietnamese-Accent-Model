{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b58cb5a4",
      "metadata": {
        "id": "b58cb5a4"
      },
      "source": [
        "# Đánh giá Mô hình Tiếng Việt có dấu\n",
        "\n",
        "Notebook này thực hiện các bước để đánh giá mô hình ngôn ngữ Tiếng Việt đã được huấn luyện. Chúng ta sẽ:\n",
        "1. Tải dữ liệu và chia thành tập huấn luyện và tập kiểm tra.\n",
        "2. Tải mô hình đã huấn luyện.\n",
        "3. Tính toán các độ đo đánh giá:\n",
        "    - Perplexity.\n",
        "    - Độ chính xác phục hồi dấu.\n",
        "    - Độ chính xác Top-3 phục hồi dấu.\n",
        "4. Trực quan hóa kết quả."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c526f83e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c526f83e",
        "outputId": "c833f7e4-afb0-4030-f879-d1ac907afb53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\tontide1\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\tontide1\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "# Download the standard 'punkt' resource (already in notebook)\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Download the 'punkt_tab' resource which appears to be missing\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Import các thư viện cần thiết\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import các module từ project của bạn\n",
        "# Đảm bảo rằng PYTHONPATH được thiết lập đúng hoặc notebook này nằm ở thư mục gốc của project\n",
        "import utils.data_loader as data_loader\n",
        "import utils.model_trainer as model_trainer\n",
        "from utils.utils import remove_vn_accent # Cần cho việc tạo từ không dấu để kiểm tra\n",
        "# from sklearn.model_selection import train_test_split # Already imported above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "LXnFufktX1s1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXnFufktX1s1",
        "outputId": "4e7b7e81-ed05-426e-ebd8-4863807d4301"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\tontide1\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f5ccaa7",
      "metadata": {
        "id": "6f5ccaa7"
      },
      "source": [
        "## 1. Tải và Chuẩn bị Dữ liệu\n",
        "\n",
        "Tải corpus và chia thành 80% cho tập huấn luyện và 20% cho tập kiểm tra.\n",
        "Lưu ý: Mô hình NLTK thường được huấn luyện trên một danh sách các câu, mỗi câu là một danh sách các token.\n",
        "Việc chia dữ liệu ở đây chủ yếu là để dành một phần dữ liệu gốc cho việc đánh giá các tác vụ cụ thể như phục hồi dấu, không nhất thiết dùng để huấn luyện lại mô hình trong notebook này."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7c67a778",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c67a778",
        "outputId": "9f4e6cac-4c6f-4f8e-8760-1957424d3186"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đang tải corpus...\n",
            "Loading corpus from: c:\\Users\\tontide1\\Desktop\\ML_ML\\data\\Train_Full\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Reading files in Train_Full: 0it [00:00, ?it/s]\n",
            "Reading files in Chinh tri Xa hoi: 100%|██████████| 6567/6567 [00:00<00:00, 14260.16it/s]\n",
            "Reading files in Doi song: 100%|██████████| 4195/4195 [00:00<00:00, 13107.67it/s]\n",
            "Reading files in Kinh doanh: 100%|██████████| 4276/4276 [00:00<00:00, 13883.13it/s]\n",
            "Reading files in Phap luat: 100%|██████████| 6656/6656 [00:00<00:00, 13953.83it/s]\n",
            "Reading files in Suc khoe: 100%|██████████| 4417/4417 [00:00<00:00, 13632.75it/s]\n",
            "Reading files in The gioi: 100%|██████████| 5716/5716 [00:00<00:00, 14963.39it/s]\n",
            "Reading files in The thao: 100%|██████████| 5667/5667 [00:00<00:00, 13476.86it/s]\n",
            "Reading files in Van hoa: 100%|██████████| 5250/5250 [00:00<00:00, 14441.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 42744 documents.\n",
            "Processing 1208363 raw sentences...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Tokenizing sentences:  26%|██▌       | 312893/1208363 [00:28<01:22, 10862.97it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mĐang tải corpus...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Giả sử load_corpus trả về một danh sách các câu (list of lists of strings)\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Ví dụ: [['tôi', 'đi', 'học'], ['trời', 'đẹp']]\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m full_corpus_sentences = \u001b[43mdata_loader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_corpus\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mĐã tải \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(full_corpus_sentences)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m câu từ corpus.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m full_corpus_sentences:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tontide1\\Desktop\\ML_ML\\utils\\data_loader.py:75\u001b[39m, in \u001b[36mload_corpus\u001b[39m\u001b[34m(data_extract_path)\u001b[39m\n\u001b[32m     73\u001b[39m raw_sents = re.split(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m[.?!]\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms+\u001b[39m\u001b[33m'\u001b[39m, full_data_string) \n\u001b[32m     74\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(raw_sents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m raw sentences...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_sents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTokenizing sentences\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Ensure sentence is not just whitespace\u001b[39;49;00m\n\u001b[32m     77\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tontide1\\scoop\\apps\\miniconda3\\current\\envs\\ML\\Lib\\site-packages\\tqdm\\std.py:1182\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1181\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[32m-> \u001b[39m\u001b[32m1182\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[32m   1183\u001b[39m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[32m   1184\u001b[39m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n\u001b[32m   1185\u001b[39m         n += \u001b[32m1\u001b[39m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Tải toàn bộ corpus (danh sách các câu, mỗi câu là danh sách các từ)\n",
        "print(\"Đang tải corpus...\")\n",
        "# Giả sử load_corpus trả về một danh sách các câu (list of lists of strings)\n",
        "# Ví dụ: [['tôi', 'đi', 'học'], ['trời', 'đẹp']]\n",
        "full_corpus_sentences = data_loader.load_corpus()\n",
        "\n",
        "print(f\"Đã tải {len(full_corpus_sentences)} câu từ corpus.\")\n",
        "\n",
        "if not full_corpus_sentences:\n",
        "    print(\"Không tải được corpus. Vui lòng kiểm tra lại data_loader.py và đường dẫn dữ liệu.\")\n",
        "else:\n",
        "    print(f\"Tải thành công {len(full_corpus_sentences)} câu.\")\n",
        "\n",
        "    # Chia dữ liệu: 80% train, 20% test\n",
        "    # Chúng ta sẽ chia danh sách các câu\n",
        "    train_sentences, test_sentences = train_test_split(full_corpus_sentences, test_size=0.2, random_state=42)\n",
        "\n",
        "    print(f\"Số câu trong tập huấn luyện: {len(train_sentences)}\")\n",
        "    print(f\"Số câu trong tập kiểm tra: {len(test_sentences)}\")\n",
        "\n",
        "    # Để tính perplexity, mô hình NLTK cần một danh sách các từ (flattened list) hoặc một iterable của các n-grams từ test_sentences\n",
        "    # Tạo test_data cho perplexity: một list các token từ test_sentences\n",
        "    test_data_tokens = [token for sentence in test_sentences for token in sentence]\n",
        "    print(f\"Tổng số token trong tập kiểm tra (dùng cho perplexity): {len(test_data_tokens)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46285795",
      "metadata": {
        "id": "46285795"
      },
      "source": [
        "## 2. Tải Mô hình đã Huấn luyện\n",
        "\n",
        "Tải mô hình đã được huấn luyện từ tệp `.pkl`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41043419",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41043419",
        "outputId": "e6f2055b-9f85-40fe-a452-61e6a38212c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đang tải mô hình từ models/kneserney_trigram_model.pkl...\n",
            "Tải mô hình thành công.\n",
            "Model type: <class 'nltk.lm.models.KneserNeyInterpolated'>\n",
            "Model order (N-gram): 3\n"
          ]
        }
      ],
      "source": [
        "MODEL_FILENAME = \"models/kneserney_trigram_model.pkl\" # Hoặc tên tệp mô hình của bạn\n",
        "\n",
        "if os.path.exists(MODEL_FILENAME):\n",
        "    print(f\"Đang tải mô hình từ {MODEL_FILENAME}...\")\n",
        "    try:\n",
        "        with open(MODEL_FILENAME, 'rb') as f:\n",
        "            model = pickle.load(f)\n",
        "        print(\"Tải mô hình thành công.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Lỗi khi tải mô hình: {e}\")\n",
        "        model = None\n",
        "else:\n",
        "    print(f\"Không tìm thấy tệp mô hình tại {MODEL_FILENAME}. Vui lòng huấn luyện mô hình trước.\")\n",
        "    model = None\n",
        "\n",
        "# In thông tin cơ bản về mô hình nếu tải thành công\n",
        "if model:\n",
        "    print(f\"Model type: {type(model)}\")\n",
        "    if hasattr(model, 'order'):\n",
        "        print(f\"Model order (N-gram): {model.order}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9b98196",
      "metadata": {
        "id": "d9b98196"
      },
      "source": [
        "## 3. Định nghĩa và Tính toán các Độ đo Đánh giá\n",
        "\n",
        "Chúng ta sẽ sử dụng các độ đo sau:\n",
        "1.  **Perplexity**: Đo lường mức độ \"ngạc nhiên\" của mô hình khi gặp một chuỗi từ mới. Giá trị càng thấp càng tốt.\n",
        "2.  **Độ chính xác Phục hồi Dấu (Accent Restoration Accuracy)**: Tỷ lệ các từ được phục hồi dấu chính xác.\n",
        "3.  **Độ chính xác Top-3 Phục hồi Dấu (Top-3 Accent Restoration Accuracy)**: Tỷ lệ các từ mà dạng đúng có dấu nằm trong 3 dự đoán hàng đầu của mô hình.\n",
        "\n",
        "**LƯU Ý QUAN TRỌNG VỀ DỰ ĐOÁN PHỤC HỒI DẤU:**\n",
        "Để tính toán độ chính xác phục hồi dấu, chúng ta cần một hàm có khả năng:\n",
        "- Nhận một từ không dấu (và có thể là ngữ cảnh xung quanh).\n",
        "- Trả về từ có dấu được dự đoán bởi mô hình (hoặc danh sách N dự đoán tốt nhất).\n",
        "\n",
        "Hàm này có thể cần được xây dựng trong `utils/predictor.py`. Ví dụ, nó có thể sử dụng mô hình ngôn ngữ để tính xác suất của các biến thể có dấu khác nhau của một từ không dấu và chọn biến thể có xác suất cao nhất.\n",
        "\n",
        "**Giả định:**\n",
        "Hiện tại, chúng ta sẽ giả định có một hàm `predict_top_n_accented(unaccented_word, context, model, n=1)` trong `utils.predictor` hoặc sẽ mô phỏng một cách đơn giản nếu chưa có.\n",
        "Đối với mô hình N-gram của NLTK, việc trực tiếp lấy \"dự đoán từ có dấu\" từ một từ không dấu không phải là một tính năng có sẵn. Mô hình N-gram tính xác suất của một chuỗi từ.\n",
        "Bạn có thể cần kết hợp `remove_vn_accent` và `gen_accents_word` từ `utils.utils` cùng với khả năng tính score của mô hình NLTK để xây dựng hàm predictor này.\n",
        "\n",
        "Ví dụ về cách `predictor` có thể hoạt động:\n",
        "1. Cho từ không dấu `w_no_accent`.\n",
        "2. Sử dụng `gen_accents_word(w_no_accent)` để lấy tất cả các biến thể có dấu `w_accented_variants`.\n",
        "3. Đối với mỗi `variant` trong `w_accented_variants`, tính điểm/xác suất của nó trong ngữ cảnh hiện tại bằng cách sử dụng `model.score(variant, context)`.\n",
        "4. Chọn variant có điểm cao nhất.\n",
        "\n",
        "Do sự phức tạp này, phần code dưới đây cho phục hồi dấu sẽ mang tính giả định cao về sự tồn tại của hàm `predict_top_n_accented_words`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dd8eb91",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dd8eb91",
        "outputId": "0802913a-de50-4ebb-db6f-33559377bf40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đang tính Perplexity trên 4313232 token...\n",
            "Lỗi khi tính perplexity: 'KneserNey' object has no attribute '_order'\n",
            "Lưu ý: Tính perplexity có thể phức tạp tùy thuộc vào cách model được huấn luyện và xử lý OOV.\n"
          ]
        }
      ],
      "source": [
        "# --- 3.1. Perplexity ---\n",
        "perplexity_score = -1\n",
        "if model and test_data_tokens:\n",
        "    try:\n",
        "        # NLTK model.perplexity() mong muốn một iterable của các token hoặc n-grams\n",
        "        # Đảm bảo test_data_tokens được padding đúng cách nếu cần cho model.vocab\n",
        "        # Hoặc sử dụng một cách tiếp cận phù hợp với cách model của bạn tính perplexity\n",
        "        # Một số mô hình NLTK có thể cần test_data được xử lý thành n-grams trước\n",
        "        # Ví dụ: list(nltk.ngrams(test_data_tokens, model.order))\n",
        "        # Tuy nhiên, nhiều mô hình chấp nhận danh sách token phẳng và tự xử lý.\n",
        "\n",
        "        # Lọc các token không có trong vocab của model để tránh lỗi (OOV - Out Of Vocabulary)\n",
        "        # Hoặc đảm bảo model của bạn xử lý OOV (ví dụ, bằng smoothing)\n",
        "        # test_data_for_perplexity = [token for token in test_data_tokens if token in model.vocab]\n",
        "        # if not test_data_for_perplexity:\n",
        "        #    print(\"Cảnh báo: Không có token nào trong test_data_tokens thuộc vocab của model. Không thể tính perplexity.\")\n",
        "        # else:\n",
        "        #    perplexity_score = model.perplexity(test_data_for_perplexity)\n",
        "\n",
        "        # Cách tiếp cận đơn giản hơn, giả sử model.perplexity xử lý OOV tokens\n",
        "        # hoặc chúng ta chấp nhận kết quả có thể bị ảnh hưởng bởi OOV\n",
        "        print(f\"Đang tính Perplexity trên {len(test_data_tokens)} token...\")\n",
        "        # Để tính perplexity chính xác, test_data_tokens nên được chuẩn bị theo cách model đã được huấn luyện\n",
        "        # (ví dụ, có thể cần thêm <s>, </s> markers nếu model được huấn luyện với chúng)\n",
        "        # Vì load_corpus không thêm các markers này, chúng ta sẽ tính trên raw tokens.\n",
        "        # Điều này có thể không hoàn toàn chính xác nếu model mong đợi padding.\n",
        "\n",
        "        # Chuyển đổi test_sentences thành dạng mà perplexity có thể tính toán\n",
        "        # Thường là một generator của các n-gram hoặc một list các token\n",
        "        # Ví dụ, nếu model là trigram:\n",
        "        # test_ngrams = [nltk.trigrams(sent) for sent in test_sentences]\n",
        "        # test_sequences = (ngram for sent_ngrams in test_ngrams for ngram in sent_ngrams)\n",
        "        # perplexity_score = model.perplexity(test_sequences)\n",
        "\n",
        "        # Cách đơn giản nhất là truyền list of tokens, nhiều model NLTK hỗ trợ điều này.\n",
        "        perplexity_score = model.perplexity(test_data_tokens)\n",
        "        print(f\"Perplexity trên tập kiểm tra: {perplexity_score:.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Lỗi khi tính perplexity: {e}\")\n",
        "        print(\"Lưu ý: Tính perplexity có thể phức tạp tùy thuộc vào cách model được huấn luyện và xử lý OOV.\")\n",
        "        perplexity_score = float('inf') # Hoặc giá trị lỗi khác\n",
        "else:\n",
        "    print(\"Mô hình chưa được tải hoặc không có dữ liệu kiểm tra để tính perplexity.\")\n",
        "    perplexity_score = float('inf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66d8df2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66d8df2f",
        "outputId": "5a1c3f95-edff-4ce5-9708-286b618493b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model order (N-gram): 3\n",
            "Đang chuẩn bị dữ liệu kiểm tra cho perplexity với padding...\n",
            "Đang tính Perplexity trên 5114532 tokens đã được padding...\n",
            "Lỗi thuộc tính khi chuẩn bị/tính perplexity: 'KneserNey' object has no attribute '_order'\n"
          ]
        }
      ],
      "source": [
        "perplexity_score = -1\n",
        "if model and test_sentences: # Sử dụng test_sentences để chuẩn bị dữ liệu có padding\n",
        "    try:\n",
        "        if not hasattr(model, 'order'):\n",
        "            raise AttributeError(\"Model không có thuộc tính 'order', không thể xác định padding cho perplexity.\")\n",
        "\n",
        "        print(f\"Model order (N-gram): {model.order}\")\n",
        "        print(\"Đang chuẩn bị dữ liệu kiểm tra cho perplexity với padding...\")\n",
        "\n",
        "        padded_test_corpus_tokens = []\n",
        "        for sent in test_sentences:\n",
        "            # Áp dụng padding giống như khi huấn luyện\n",
        "            # Tham số 'n' cho pad_both_ends là bậc của N-gram (model.order)\n",
        "            # Mặc định left_pad_symbol=\"<s>\", right_pad_symbol=\"</s>\"\n",
        "            padded_sent = list(nltk.lm.preprocessing.pad_both_ends(sent, n=model.order))\n",
        "            # print(padded_sent)\n",
        "            padded_test_corpus_tokens.extend(padded_sent)\n",
        "\n",
        "        if not padded_test_corpus_tokens:\n",
        "            print(\"Cảnh báo: Corpus kiểm tra sau khi padding bị rỗng.\")\n",
        "            perplexity_score = float('inf')\n",
        "        else:\n",
        "            print(f\"Đang tính Perplexity trên {len(padded_test_corpus_tokens)} tokens đã được padding...\")\n",
        "            perplexity_score = model.perplexity(padded_test_corpus_tokens)\n",
        "            print(f\"Perplexity trên tập kiểm tra: {perplexity_score:.4f}\")\n",
        "\n",
        "    except AttributeError as ae:\n",
        "        print(f\"Lỗi thuộc tính khi chuẩn bị/tính perplexity: {ae}\")\n",
        "        perplexity_score = float('inf')\n",
        "    except Exception as e:\n",
        "        print(f\"Lỗi khi tính perplexity: {e}\")\n",
        "        print(\"Lưu ý: Tính perplexity có thể phức tạp tùy thuộc vào cách model được huấn luyện và xử lý OOV.\")\n",
        "        perplexity_score = float('inf')\n",
        "else:\n",
        "    print(\"Mô hình chưa được tải hoặc không có dữ liệu kiểm tra (test_sentences) để tính perplexity.\")\n",
        "    perplexity_score = float('inf')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fc6e131",
      "metadata": {
        "id": "3fc6e131"
      },
      "source": [
        "### Giả định hàm `predict_top_n_accented_words`\n",
        "Do chưa có hàm `predict_top_n_accented_words` trong `utils.predictor`, chúng ta sẽ tạo một hàm giả định ở đây để minh họa.\n",
        "Trong thực tế, bạn cần xây dựng hàm này một cách cẩn thận dựa trên mô hình ngôn ngữ của mình."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cb7f6d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cb7f6d2",
        "outputId": "ee408984-eadb-436b-953c-018a62518771"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đang đánh giá độ chính xác phục hồi dấu trên 200325 câu kiểm tra...\n",
            "Đã xử lý 100/200325 câu...\n",
            "Đã xử lý 200/200325 câu...\n",
            "Đã xử lý 300/200325 câu...\n",
            "Đã xử lý 400/200325 câu...\n",
            "Đã xử lý 500/200325 câu...\n",
            "Đã xử lý 600/200325 câu...\n"
          ]
        }
      ],
      "source": [
        "# --- Giả định hàm predictor ---\n",
        "# Đây là một hàm GIẢ ĐỊNH. Bạn cần thay thế bằng logic thực tế của mình.\n",
        "# Hàm này nên nằm trong utils/predictor.py\n",
        "def predict_top_n_accented_words_mock(unaccented_word: str, context: list[str], model_lm, n: int = 3) -> list[str]:\n",
        "    \"\"\"\n",
        "    Hàm MOCK để dự đoán N từ có dấu khả năng nhất cho một từ không dấu.\n",
        "    Trong thực tế, hàm này sẽ sử dụng model_lm để tính điểm các biến thể có dấu.\n",
        "    \"\"\"\n",
        "    # Bước 1: Tạo các biến thể có dấu (sử dụng utils.utils.gen_accents_word nếu có)\n",
        "    # Giả sử gen_accents_word tồn tại và hoạt động tốt\n",
        "    try:\n",
        "        from utils.utils import gen_accents_word\n",
        "        possible_accented_words = list(gen_accents_word(unaccented_word))\n",
        "    except ImportError: # Fallback nếu không import được\n",
        "        # Tạo một vài biến thể giả định đơn giản\n",
        "        if unaccented_word == \"hoc\":\n",
        "            possible_accented_words = [\"học\", \"hóc\", \"hộc\"]\n",
        "        elif unaccented_word == \"troi\":\n",
        "            possible_accented_words = [\"trời\", \"trôi\", \"trối\"]\n",
        "        elif unaccented_word == \"dep\":\n",
        "            possible_accented_words = [\"đẹp\", \"dẹp\"]\n",
        "        else: # Trả về chính từ không dấu nếu không có quy tắc\n",
        "            possible_accented_words = [unaccented_word]\n",
        "\n",
        "    if not possible_accented_words:\n",
        "        return [unaccented_word] # Trả về từ gốc nếu không có biến thể\n",
        "\n",
        "    # Bước 2: Tính điểm cho mỗi biến thể (đây là phần phức tạp cần model_lm)\n",
        "    # Vì đây là mock, chúng ta sẽ trả về ngẫu nhiên hoặc dựa trên thứ tự đơn giản\n",
        "    # Trong thực tế: scores = [model_lm.score(variant, context) for variant in possible_accented_words]\n",
        "    # sorted_variants = [v for _, v in sorted(zip(scores, possible_accented_words), reverse=True)]\n",
        "\n",
        "    # Mock logic: chỉ trả về tối đa N phần tử đầu tiên từ list (hoặc ngẫu nhiên)\n",
        "    random.shuffle(possible_accented_words) # Giả vờ là đã sắp xếp theo score\n",
        "    return possible_accented_words[:n]\n",
        "\n",
        "# --- 3.2. & 3.3. Độ chính xác Phục hồi Dấu ---\n",
        "correct_predictions = 0\n",
        "top_n_correct_predictions = 0\n",
        "total_words_evaluated = 0\n",
        "N_TOP = 3 # Cho Top-N accuracy\n",
        "\n",
        "accent_restoration_results = [] # Lưu trữ (original, unaccented, predicted, is_correct, is_in_top_n)\n",
        "\n",
        "if model and test_sentences:\n",
        "    print(f\"Đang đánh giá độ chính xác phục hồi dấu trên {len(test_sentences)} câu kiểm tra...\")\n",
        "    for i, sentence in enumerate(test_sentences):\n",
        "        if i % 100 == 0 and i > 0: # In tiến trình\n",
        "            print(f\"Đã xử lý {i}/{len(test_sentences)} câu...\")\n",
        "\n",
        "        context = [] # Ngữ cảnh cho mô hình N-gram (ví dụ: N-1 từ trước đó)\n",
        "        for original_word in sentence:\n",
        "            if not original_word.strip() or not any(c.isalpha() for c in original_word): # Bỏ qua từ rỗng hoặc không có chữ cái\n",
        "                context.append(original_word) # Vẫn thêm vào context\n",
        "                continue\n",
        "\n",
        "            unaccented_word = remove_vn_accent(original_word)\n",
        "\n",
        "            # Lấy dự đoán từ mô hình (sử dụng hàm mock)\n",
        "            # Trong thực tế, context sẽ là N-1 từ đứng trước `original_word`\n",
        "            # Ví dụ, nếu model là trigram (order=3), context là 2 từ trước đó.\n",
        "            # current_context = context[-(model.order - 1):] if hasattr(model, 'order') else []\n",
        "            predicted_top_n = predict_top_n_accented_words_mock(unaccented_word, context, model, n=N_TOP)\n",
        "\n",
        "            predicted_word = \"\"\n",
        "            is_correct = False\n",
        "            is_in_top_n = False\n",
        "\n",
        "            if predicted_top_n:\n",
        "                predicted_word = predicted_top_n[0] # Dự đoán tốt nhất\n",
        "                if predicted_word == original_word:\n",
        "                    correct_predictions += 1\n",
        "                    is_correct = True\n",
        "\n",
        "                if original_word in predicted_top_n:\n",
        "                    top_n_correct_predictions += 1\n",
        "                    is_in_top_n = True\n",
        "\n",
        "            accent_restoration_results.append({\n",
        "                \"original\": original_word,\n",
        "                \"unaccented\": unaccented_word,\n",
        "                \"predicted_top1\": predicted_word,\n",
        "                \"predicted_topN\": predicted_top_n,\n",
        "                \"is_correct_top1\": is_correct,\n",
        "                \"is_in_topN\": is_in_top_n\n",
        "            })\n",
        "            total_words_evaluated += 1\n",
        "            context.append(original_word) # Cập nhật context cho từ tiếp theo\n",
        "\n",
        "    if total_words_evaluated > 0:\n",
        "        accuracy = (correct_predictions / total_words_evaluated) * 100\n",
        "        top_n_accuracy = (top_n_correct_predictions / total_words_evaluated) * 100\n",
        "        print(f\"Tổng số từ đã đánh giá (phục hồi dấu): {total_words_evaluated}\")\n",
        "        print(f\"Độ chính xác phục hồi dấu (Accuracy): {accuracy:.2f}%\")\n",
        "        print(f\"Độ chính xác Top-{N_TOP} phục hồi dấu: {top_n_accuracy:.2f}%\")\n",
        "    else:\n",
        "        print(\"Không có từ nào được đánh giá cho việc phục hồi dấu.\")\n",
        "        accuracy = 0\n",
        "        top_n_accuracy = 0\n",
        "else:\n",
        "    print(\"Mô hình chưa được tải hoặc không có dữ liệu kiểm tra để đánh giá phục hồi dấu.\")\n",
        "    accuracy = 0\n",
        "    top_n_accuracy = 0\n",
        "\n",
        "# Chuyển kết quả chi tiết thành DataFrame để dễ xem\n",
        "df_results = pd.DataFrame(accent_restoration_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b25957dc",
      "metadata": {
        "id": "b25957dc"
      },
      "source": [
        "### Xem một vài ví dụ về kết quả phục hồi dấu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecef185f",
      "metadata": {
        "id": "ecef185f"
      },
      "outputs": [],
      "source": [
        "if not df_results.empty:\n",
        "    print(\"Một vài ví dụ về kết quả phục hồi dấu (Top-1):\")\n",
        "    print(df_results[df_results['original'] != df_results['predicted_top1']].sample(min(10, len(df_results[df_results['original'] != df_results['predicted_top1']]))))\n",
        "\n",
        "    print(f\"Một vài ví dụ dự đoán Top-1 đúng:\")\n",
        "    print(df_results[df_results['is_correct_top1'] == True].sample(min(5, len(df_results[df_results['is_correct_top1'] == True]))))\n",
        "\n",
        "    print(f\"Một vài ví dụ dự đoán Top-1 sai nhưng đúng trong Top-{N_TOP}:\")\n",
        "    print(df_results[(df_results['is_correct_top1'] == False) & (df_results['is_in_topN'] == True)].sample(min(5, len(df_results[(df_results['is_correct_top1'] == False) & (df_results['is_in_topN'] == True)]))))\n",
        "else:\n",
        "    print(\"Không có kết quả chi tiết để hiển thị.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "281624e4",
      "metadata": {
        "id": "281624e4"
      },
      "source": [
        "## 4. Trực quan hóa Kết quả\n",
        "\n",
        "Vẽ biểu đồ thể hiện các độ đo đã tính toán."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b762ad5",
      "metadata": {
        "id": "5b762ad5"
      },
      "outputs": [],
      "source": [
        "metrics_names = ['Perplexity', f'Accuracy (Top-1)', f'Accuracy (Top-{N_TOP})']\n",
        "# Perplexity có thang đo khác, nên có thể không vẽ chung hoặc cần chuẩn hóa\n",
        "# Ở đây chúng ta sẽ vẽ Accuracy riêng\n",
        "accuracy_scores = [accuracy, top_n_accuracy]\n",
        "accuracy_labels = [f'Accuracy (Top-1)', f'Accuracy (Top-{N_TOP})']\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Biểu đồ cho Perplexity (nếu có giá trị hợp lệ)\n",
        "if perplexity_score != float('inf') and perplexity_score != -1:\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.barplot(x=[\"Perplexity\"], y=[perplexity_score])\n",
        "    plt.title(f'Perplexity Score: {perplexity_score:.2f}')\n",
        "    plt.ylabel(\"Giá trị Perplexity (càng thấp càng tốt)\")\n",
        "else:\n",
        "    print(\"Không có giá trị Perplexity hợp lệ để vẽ.\")\n",
        "    # Tạo một plot trống nếu không có perplexity\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.text(0.5, 0.5, 'Perplexity N/A', ha='center', va='center', fontsize=12)\n",
        "    plt.title('Perplexity Score')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "\n",
        "# Biểu đồ cho Độ chính xác Phục hồi Dấu\n",
        "plt.subplot(1, 2, 2)\n",
        "if total_words_evaluated > 0:\n",
        "    bars = sns.barplot(x=accuracy_labels, y=accuracy_scores, palette=\"viridis\")\n",
        "    plt.title('Độ chính xác Phục hồi Dấu')\n",
        "    plt.ylabel('Tỷ lệ (%)')\n",
        "    plt.ylim(0, 100) # Giới hạn trục y từ 0 đến 100%\n",
        "    for bar in bars.patches:\n",
        "        plt.text(bar.get_x() + bar.get_width() / 2,\n",
        "                 bar.get_height() + 0.5,\n",
        "                 f'{bar.get_height():.2f}%',\n",
        "                 ha='center', va='bottom')\n",
        "else:\n",
        "    plt.text(0.5, 0.5, 'Accuracy N/A', ha='center', va='center', fontsize=12)\n",
        "    plt.title('Độ chính xác Phục hồi Dấu')\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64592b53",
      "metadata": {
        "id": "64592b53"
      },
      "source": [
        "## 5. Phân tích Lỗi (Error Analysis) - Tùy chọn\n",
        "\n",
        "Xem xét các trường hợp mô hình dự đoán sai để hiểu rõ hơn về điểm yếu của nó."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e3dfc6c",
      "metadata": {
        "id": "4e3dfc6c"
      },
      "outputs": [],
      "source": [
        "if not df_results.empty:\n",
        "    # Các trường hợp Top-1 dự đoán sai\n",
        "    errors_df = df_results[df_results['is_correct_top1'] == False]\n",
        "    print(f\"Số lượng dự đoán sai (Top-1): {len(errors_df)} / {total_words_evaluated}\")\n",
        "\n",
        "    if not errors_df.empty:\n",
        "        print(\"10 ví dụ ngẫu nhiên về các lỗi dự đoán (Top-1):\")\n",
        "        # Hiển thị 'original', 'unaccented', 'predicted_top1'\n",
        "        print(errors_df[['original', 'unaccented', 'predicted_top1']].sample(min(10, len(errors_df))))\n",
        "\n",
        "        # Thống kê các lỗi phổ biến (ví dụ: những từ nào hay bị sai nhất)\n",
        "        # (Phần này có thể phức tạp hơn và tùy thuộc vào nhu cầu)\n",
        "        common_errors = errors_df.groupby(['original', 'predicted_top1']).size().sort_values(ascending=False)\n",
        "        print(\"Các cặp (từ gốc, từ dự đoán sai) phổ biến nhất:\")\n",
        "        print(common_errors.head(10))\n",
        "    else:\n",
        "        print(\"Không có lỗi nào trong dự đoán Top-1 (hoặc không có từ nào được đánh giá).\")\n",
        "else:\n",
        "    print(\"Không có kết quả chi tiết để phân tích lỗi.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d86014a3",
      "metadata": {
        "id": "d86014a3"
      },
      "source": [
        "## 6. Kết luận và Hướng Phát triển Tiếp theo\n",
        "\n",
        "Dựa trên kết quả đánh giá:\n",
        "- Mô hình hoạt động tốt như thế nào?\n",
        "- Các điểm mạnh và điểm yếu là gì?\n",
        "- Có thể cải thiện mô hình bằng cách nào (ví dụ: thêm dữ liệu, thay đổi kiến trúc mô hình, tinh chỉnh tham số, cải thiện hàm predictor)?\n",
        "\n",
        "(Điền nhận xét của bạn vào đây)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
